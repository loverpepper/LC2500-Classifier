{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280},{"sourceId":12675462,"sourceType":"datasetVersion","datasetId":8010262}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport os\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nfrom skimage.feature import graycomatrix, graycoprops\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\nimport tensorflow as tf\nprint(f'The tensorflow version is {tf.__version__}')\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, mixed_precision\nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:10:21.205154Z","iopub.execute_input":"2025-08-05T08:10:21.205438Z","iopub.status.idle":"2025-08-05T08:10:35.522962Z","shell.execute_reply.started":"2025-08-05T08:10:21.205415Z","shell.execute_reply":"2025-08-05T08:10:35.522332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set'\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    flists = os.listdir(foldpath)\n    for f in flists:\n        f_paths = os.path.join(foldpath, f)\n        filelist = os.listdir(f_paths)\n        for file in filelist:\n            fpath = os.path.join(f_paths, file)\n            filepaths.append(fpath)\n            if f == 'colon_aca':\n                labels.append('Colon Adenocarcinoma')\n            elif f == 'colon_n':\n                labels.append('Colon Benign Tissue')\n            elif f == 'lung_aca':\n                labels.append('Lung Adenocarcinoma')\n            elif f == 'lung_n':\n                labels.append('Lung Benign Tissue')\n            elif f == 'lung_scc':\n                labels.append('Lung Squamous Cell Carcinoma')\n\nFseries = pd.Series(filepaths, name = 'filepaths')\nLseries = pd.Series(labels, name = 'labels')\ndf = pd.concat([Fseries, Lseries], axis = 1)\n\ndf.head()\nprint(df.labels.value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:10:35.523989Z","iopub.execute_input":"2025-08-05T08:10:35.524503Z","iopub.status.idle":"2025-08-05T08:10:35.861153Z","shell.execute_reply.started":"2025-08-05T08:10:35.524483Z","shell.execute_reply":"2025-08-05T08:10:35.860556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:10:35.861848Z","iopub.execute_input":"2025-08-05T08:10:35.862046Z","iopub.status.idle":"2025-08-05T08:10:35.882448Z","shell.execute_reply.started":"2025-08-05T08:10:35.862030Z","shell.execute_reply":"2025-08-05T08:10:35.881869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = cv2.imread(df.filepaths[0])  # BGR格式\n\nheight, width, channels = img.shape\nprint(f\"图像尺寸: {width}x{height}, 通道数: {channels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:10:35.884004Z","iopub.execute_input":"2025-08-05T08:10:35.884205Z","iopub.status.idle":"2025-08-05T08:10:35.923164Z","shell.execute_reply.started":"2025-08-05T08:10:35.884188Z","shell.execute_reply":"2025-08-05T08:10:35.922625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, temp_df = train_test_split(\n    df,\n    test_size = 0.2,\n    shuffle = True,\n    stratify = df['labels'],\n    random_state = 123\n)\n\nvalid_df, test_df = train_test_split(\n    temp_df,\n    test_size = 0.4,\n    shuffle = True,\n    stratify = temp_df['labels'],\n    random_state = 123\n)\n\nprint(f'the train dataset size is {len(train_df)}')\nprint(f'the validation dataset size is {len(valid_df)}')\nprint(f'the test dataset size is {len(test_df)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:10:35.923742Z","iopub.execute_input":"2025-08-05T08:10:35.923917Z","iopub.status.idle":"2025-08-05T08:10:35.961125Z","shell.execute_reply.started":"2025-08-05T08:10:35.923903Z","shell.execute_reply":"2025-08-05T08:10:35.960549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 64\nimage_size = (224, 224)\nimage_shape = (image_size[0], image_size[1], channels)\n\n\n# Load training and validation sets\ndatagen = ImageDataGenerator(rescale=1./255)\ntrain_gen = datagen.flow_from_dataframe(\n    dataframe = train_df,\n    x_col='filepaths',\n    y_col='labels',\n    target_size = image_size,\n    class_mode='categorical',\n    # color_mode= 'rgb',\n    shuffle=True,\n    batch_size=batch_size\n)\n\nvalid_gen = datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    x_col = 'filepaths',\n    y_col = 'labels',\n    target_size = image_size,\n    class_mode='categorical',\n    # color_mode= 'rgb',\n    shuffle=True,\n    batch_size=batch_size\n)\n\ntest_gen = datagen.flow_from_dataframe(\n    dataframe = test_df,\n    x_col = 'filepaths',\n    y_col = 'labels',\n    target_size = image_size,\n    class_mode='categorical',\n    # color_mode= 'rgb',\n    shuffle=False,\n    batch_size=batch_size\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:10:35.961739Z","iopub.execute_input":"2025-08-05T08:10:35.961912Z","iopub.status.idle":"2025-08-05T08:11:17.978598Z","shell.execute_reply.started":"2025-08-05T08:10:35.961898Z","shell.execute_reply":"2025-08-05T08:11:17.977824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())         # defines list of dictionary's keys (class names)\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\nplt.figure(figsize=(20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    image = images[i]   # No need to divide by 255 again\n    plt.imshow(image)  # Display image (if it's BGR, convert to RGB as necessary)\n    index = np.argmax(labels[i])  # Get image index (one-hot to class index)\n    class_name = classes[index]   # Get class name from index\n    plt.title(class_name, color='blue', fontsize=12)\n    plt.axis('off')  # Hide axis for cleaner image display\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:11:17.979362Z","iopub.execute_input":"2025-08-05T08:11:17.979571Z","iopub.status.idle":"2025-08-05T08:11:20.904248Z","shell.execute_reply.started":"2025-08-05T08:11:17.979542Z","shell.execute_reply":"2025-08-05T08:11:20.903302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(g_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:11:20.905364Z","iopub.execute_input":"2025-08-05T08:11:20.905939Z","iopub.status.idle":"2025-08-05T08:11:20.911249Z","shell.execute_reply.started":"2025-08-05T08:11:20.905904Z","shell.execute_reply":"2025-08-05T08:11:20.910483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Establish model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n\n# 定义输入\ninput_shape = (224, 224, 3)\ninputs = Input(shape=input_shape)\n\n# 卷积块 1\nx = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(inputs)\nx = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = MaxPooling2D((2, 2))(x)\n\n# 卷积块 2\nx = Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = MaxPooling2D((2, 2))(x)\n\n# 卷积块 3\nx = Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = MaxPooling2D((2, 2))(x)\n\n# 卷积块 4\nx = Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = MaxPooling2D((2, 2))(x)\n\n# 卷积块 5\nx = Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")(x)\nx = MaxPooling2D((2, 2))(x)\n\n# 全连接层\nx = Flatten()(x)\nx = Dense(256, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\noutputs = Dense(5, activation=\"softmax\")(x)\n\n# 构建模型\nmodel = Model(inputs=inputs, outputs=outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:11:20.912100Z","iopub.execute_input":"2025-08-05T08:11:20.912324Z","iopub.status.idle":"2025-08-05T08:11:23.381559Z","shell.execute_reply.started":"2025-08-05T08:11:20.912296Z","shell.execute_reply":"2025-08-05T08:11:23.380798Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train and Evaluate","metadata":{}},{"cell_type":"code","source":"mixed_precision.set_global_policy('mixed_float16')\nepochs = 20\n\nmodel.compile(\n    optimizer = Adamax(learning_rate = 0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\ncheckpoint = ModelCheckpoint(\n    filepath='best_model.h5',   \n    monitor='val_accuracy',     \n    save_best_only=True,        \n    mode='max',                 \n    verbose=1\n)\n\nhistory = model.fit(\n    train_gen,\n    epochs=epochs,\n    verbose=1,\n    validation_data = valid_gen,\n    callbacks = checkpoint\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T08:11:23.383805Z","iopub.execute_input":"2025-08-05T08:11:23.384016Z","iopub.status.idle":"2025-08-05T09:01:36.000045Z","shell.execute_reply.started":"2025-08-05T08:11:23.384000Z","shell.execute_reply":"2025-08-05T09:01:35.999445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = load_model('/kaggle/input/best-model/best_model.h5')\n\ntest_loss, test_acc = model.evaluate(test_gen, verbose=1)\nprint(f\"测试集准确率：{test_acc:.4f}\")\n\nimport matplotlib.pyplot as plt\n\nprint('训练过程测试集和验证集Accuracy变化：')\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:01:36.001064Z","iopub.execute_input":"2025-08-05T09:01:36.001332Z","iopub.status.idle":"2025-08-05T09:02:00.512938Z","shell.execute_reply.started":"2025-08-05T09:01:36.001308Z","shell.execute_reply":"2025-08-05T09:02:00.512351Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"from PIL import Image # 加载图像\n\ncorrect_preds = 0\ntotal_preds = 10  # 抽取的图像数量\n\n# 抽取 10 个图像并计算正确率\nfor _ in range(total_preds):\n    row = df.sample(n=1).iloc[0]  # 随机选择一行\n    img_path = row['filepaths']\n    true_label = row['labels']\n\n    # ======================\n    # 读取并预处理图像\n    image = Image.open(img_path)\n    img = image.resize((224, 224))  # 调整到目标大小\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = img_array / 255.0  # 归一化\n    img_array = tf.expand_dims(img_array, 0)  # 扩展为 batch_size = 1\n\n    # ======================\n    # 预测\n    preds = model.predict(img_array)\n    pred_class = np.argmax(preds, axis=1)[0]  # 获取预测类别索引\n\n    # 获取类别名称\n    class_indices = {v: k for k, v in train_gen.class_indices.items()}  # 获取类别映射\n    pred_label = class_indices[pred_class]\n\n    # 比较真实标签与预测标签\n    if true_label == pred_label:\n        correct_preds += 1\n\n    print(f\"真实标签: {true_label}, 预测标签: {pred_label}, 概率: {preds[0][pred_class]:.4f}\")\n\n# 计算准确率\naccuracy = correct_preds / total_preds\nprint(f\"\\n总的准确率: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:00.513729Z","iopub.execute_input":"2025-08-05T09:02:00.513988Z","iopub.status.idle":"2025-08-05T09:02:02.701246Z","shell.execute_reply.started":"2025-08-05T09:02:00.513971Z","shell.execute_reply":"2025-08-05T09:02:02.700552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-CAM Heatmap","metadata":{}},{"cell_type":"code","source":"# 图像尺寸是 224x224\nimg_size = (224, 224)\n\n# 从 DataFrame 中随机取一张图像\nrow = df.sample(n=1).iloc[0]\nimg_path = row['filepaths']\ntrue_label = row['labels']\n\nimport IPython\nIPython.display.display(IPython.display.Image(img_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:02.702066Z","iopub.execute_input":"2025-08-05T09:02:02.702345Z","iopub.status.idle":"2025-08-05T09:02:02.711875Z","shell.execute_reply.started":"2025-08-05T09:02:02.702320Z","shell.execute_reply":"2025-08-05T09:02:02.711178Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Grad-Cam 算法","metadata":{}},{"cell_type":"code","source":"def get_img_array(img_path, img_size):\n    image = Image.open(img_path)\n    img = image.resize((224, 224))  # 调整到目标大小\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    \n    # 如果你的模型是用 rescale=1./255 训练的，就归一化\n    img_array = img_array / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    return img_array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = keras.models.Model(\n        inputs=model.inputs, \n        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:02.712643Z","iopub.execute_input":"2025-08-05T09:02:02.712860Z","iopub.status.idle":"2025-08-05T09:02:02.728329Z","shell.execute_reply.started":"2025-08-05T09:02:02.712835Z","shell.execute_reply":"2025-08-05T09:02:02.727673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 获取你模型中最后一个卷积层的名字\nlast_conv_layer_name = [layer.name for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)][-1]\n\n# 生成 heatmap\nimg_array = get_img_array(img_path, img_size)\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\nplt.matshow(heatmap)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:02.729209Z","iopub.execute_input":"2025-08-05T09:02:02.729515Z","iopub.status.idle":"2025-08-05T09:02:04.142572Z","shell.execute_reply.started":"2025-08-05T09:02:02.729494Z","shell.execute_reply":"2025-08-05T09:02:04.141750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    # Load the original image\n    img = keras.utils.load_img(img_path)\n    img = keras.utils.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = mpl.colormaps[\"jet\"]\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.utils.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    IPython.display.display(IPython.display.Image(cam_path))\n\n\nsave_and_display_gradcam(img_path, heatmap)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:02:04.143447Z","iopub.execute_input":"2025-08-05T09:02:04.143888Z","iopub.status.idle":"2025-08-05T09:02:04.175423Z","shell.execute_reply.started":"2025-08-05T09:02:04.143862Z","shell.execute_reply":"2025-08-05T09:02:04.174660Z"}},"outputs":[],"execution_count":null}]}